{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64363c52-0d98-4be1-bb7e-f98cfe43bec2",
   "metadata": {},
   "source": [
    "# Spatial analysis\n",
    "\n",
    "After running PIPEX on our images, we would like to load the images and results into a `SpatialData` Object. Afterwards, we can interactively look at it with Napari  or run more spatial analyses with SquidPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269075d2-940a-40f9-9cea-859bad10cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import read_h5ad, AnnData\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from napari_spatialdata import Interactive\n",
    "import numpy as np\n",
    "from spatialdata import SpatialData\n",
    "from spatialdata.models import Image2DModel, Labels2DModel, TableModel\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9be6ee-d5e4-4372-b50c-fd1753ab201b",
   "metadata": {},
   "source": [
    "## Data download\n",
    "\n",
    "You could use the data generated during the course while running PIPEX. Or you might also download the data from [here](https://ell-vault.stanford.edu/dav/fredbn/www/I2K/pipex_data.zip) and unzip it into the data folder inside the `I2K2024-MTIWOKSHOP` folder.\n",
    "\n",
    "If it didn't work, you can uncomment the lines in the cell below and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289eb04-3d96-42a8-8608-e56ae5740867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import download_and_unzip\n",
    "\n",
    "# file_url = \"https://ell-vault.stanford.edu/dav/fredbn/www/I2K/pipex_data.zip\"\n",
    "# output_folder = '../data'\n",
    "# download_and_unzip(file_url, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f186f7b-9432-4d3d-b5af-086338ea6211",
   "metadata": {},
   "source": [
    "## SpatialData construction\n",
    "\n",
    "We can begin by stating the directories of the pipex results, images and where we would like to store the SPatialData Objects as a Zarr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac4d0c8-b260-4fb1-99f2-d5b10e0b911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipex_dir = Path(\"../data/data/analysis\")\n",
    "images_dir = Path(\"../data/data\")\n",
    "sdata_file = Path(\"../data/pipex.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c152258-5216-487a-8882-5282c6c627bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = []\n",
    "channel_imgs = []\n",
    "for channel_img_file in sorted(images_dir.glob(\"*.tif\")):\n",
    "    channel_img = tifffile.imread(channel_img_file)\n",
    "    channels.append(channel_img_file.stem)\n",
    "    channel_imgs.append(channel_img)\n",
    "img = np.stack(channel_imgs)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ee376-cb38-4a13-8e65-07d0d387e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = pipex_dir / \"segmentation_data.npy\"\n",
    "labels = np.load(labels_file).astype(np.uint16)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_file = pipex_dir / \"downstream\" / \"anndata_TissUUmaps.h5ad\"\n",
    "cells = read_h5ad(cells_file) \n",
    "cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac67430",
   "metadata": {},
   "source": [
    "We need to add some information to relate the AnnData information in the table to the cells detected and shown in the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc412ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells.uns[\"spatialdata_attrs\"] = {\"region\": [\"labels\"],\n",
    "                                  \"region_key\": \"sample_id\",\n",
    "                                  \"instance_key\": \"id\"}\n",
    "cells.obs[\"sample_id\"] = \"labels\"\n",
    "cells.obs[\"sample_id\"] = cells.obs[\"sample_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fffd39-97ea-4e33-bd4d-9d55e5565e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = SpatialData(\n",
    "    images={\"images\": Image2DModel.parse(img, dims=(\"c\", \"y\", \"x\"), c_coords=channels)},\n",
    "    labels={\"labels\": Labels2DModel.parse(labels, dims=(\"y\", \"x\"))},\n",
    "    tables={\"table\": TableModel.parse(cells)},\n",
    ")\n",
    "sdata.write(sdata_file, overwrite=True)\n",
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c6579-1d98-464b-af3b-80233b344d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf1707-bdb0-4a37-9c79-7663999a06a0",
   "metadata": {},
   "source": [
    "## Spatial single-cell analysis\n",
    "\n",
    "We can begin by reading the spatial data file constructed on the previous subsection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0250b31-21c1-498e-bd88-666759bb333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_file = \"../data/pipex.zarr\"\n",
    "sdata = SpatialData.read(sdata_file)\n",
    "sdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5eada",
   "metadata": {},
   "source": [
    "We can import squidpy and scanpy to perform analysis on our files, but most of these analyses have already been performed and are saved in the appended tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e41b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "import squidpy as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"table\"].var_names, sdata[\"table\"].obs_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca64d3",
   "metadata": {},
   "source": [
    "We can visualize the lolcation of every cluster in the plot with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(sdata[\"table\"], shape=None, color=\"leiden\", size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6044ea",
   "metadata": {},
   "source": [
    "For the following, we will do some of the steps presented in [this link](https://www.sc-best-practices.org/spatial/neighborhood.html#). We can compute a spatial graph by running `spatial_neighbours` function in the `gr` module (graph). And then we can run `spatial_scatter` once more from the `pl` (plot) module, adding the `connectivity_key` parameter.\n",
    "\n",
    "*Note*: Feel free to play around with the radius parameter and see what happens when you increase it to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(sdata[\"table\"], radius=30.0, coord_type=\"generic\")\n",
    "sq.pl.spatial_scatter(\n",
    "    sdata[\"table\"],\n",
    "    color=\"leiden\",\n",
    "    connectivity_key=\"spatial_connectivities\",\n",
    "    edges_color=\"black\",\n",
    "    shape=None,\n",
    "    edges_width=1,\n",
    "    size=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7760d",
   "metadata": {},
   "source": [
    "We could as well rerun and plot (or only plot) the neighbourhood enrichment test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262dad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sq.gr.spatial_neighbors(sdata[\"cells\"])\n",
    "# sq.gr.nhood_enrichment(sdata[\"cells\"], cluster_key=\"leiden\")\n",
    "sq.pl.nhood_enrichment(sdata[\"table\"], cluster_key=\"leiden\", figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638991b7",
   "metadata": {},
   "source": [
    "We can calculate the interaction matrix which is the sum of all interactions happenning in the tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cfbfb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.interaction_matrix(sdata[\"table\"], cluster_key=\"leiden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.interaction_matrix(sdata[\"table\"], cluster_key=\"leiden\", method=\"average\", figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5a3b9",
   "metadata": {},
   "source": [
    "We could overlay the graphs with the an image to see how it looks like.\n",
    "\n",
    "*Note*: This part is under development and might work for spatial transcriptomics with spots, such as visium, but it was not working with our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b8ea390",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_key = \"spatial\"\n",
    "library_id = \"labels\"\n",
    "sdata[\"cells\"] = sdata[\"table\"]\n",
    "\n",
    "sdata[\"cells\"].uns[spatial_key] = {library_id: {}}\n",
    "sdata[\"cells\"].uns[spatial_key][library_id][\"images\"] = {}\n",
    "sdata[\"cells\"].uns[spatial_key][library_id][\"images\"] = {\"hires\": sdata[\"images\"].loc[\"DAPI\"].to_numpy()}\n",
    "sdata[\"cells\"].uns[spatial_key][library_id][\"scalefactors\"] = {\n",
    "    \"tissue_hires_scalef\": 1,\n",
    "    \"spot_diameter_fullres\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"cells\"].uns['spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(sdata[\"cells\"], color=\"leiden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d630a57",
   "metadata": {},
   "source": [
    "## Generating SpatialData Object from csv file\n",
    "\n",
    "In case wyou have some extra time (or extra curiosity), we could go one step back and load the csv file into SpatialData object. Once this is done, we could run our own dimensionality reduction and clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "483e531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipex_dir = Path(\"../data/data/analysis\")\n",
    "images_dir = Path(\"../data/data\")\n",
    "sdata_file = Path(\"../data/pipex.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc451587",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = []\n",
    "channel_imgs = []\n",
    "for channel_img_file in sorted(images_dir.glob(\"*.tif\")):\n",
    "    channel_img = tifffile.imread(channel_img_file)\n",
    "    channels.append(channel_img_file.stem)\n",
    "    channel_imgs.append(channel_img)\n",
    "img = np.stack(channel_imgs)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a062890",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = pipex_dir / \"segmentation_data.npy\"\n",
    "labels = np.load(labels_file).astype(np.uint16)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_file = pipex_dir /  \"cell_data_ANNOTATED.csv\"\n",
    "cells = pd.read_csv(cells_file)\n",
    "cells.kmeans_annotated.fillna(\"None\", inplace=True)\n",
    "cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e966560",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = [\"ARL13B\", \"ATM\", \"Bcl-2\", \"Beta-actin\", \"CD107a\", \"CD11c\", \"CD14\", \"CD163\", \n",
    "           \"CD20\", \"CD31\", \"CD34\", \"CD39\", \"CD3e\", \"CD4\", \"CD40\", \"CD44\", \"CD45\", \"CD56\", \n",
    "           \"CD68\", \"CD8\", \"Caveolin\", \"Collagen_IV\", \"DAPI\", \"E-cadherin\", \"ER\", \"EpCam\", \n",
    "           \"GP100\", \"HIF1A\", \"HLA-A\", \"HLA-DR\", \"Histone_H3_pSer28\", \"ICOS\", \"IDO1\", \"Keratin_5\",\n",
    "             \"Keratin_8-18\", \"Ki67\", \"PCNA\", \"PCNT\", \"PD-1\", \"PD-L1\", \"Pan-Cytokeratin\", \"Podoplanin\", \n",
    "             \"SMA\", \"SOX2\", \"TOX\", \"VISTA\", \"Vimentin\", \"b-Catenin1\", \"iNOS\"]\n",
    "\n",
    "# Create core of AnnData object\n",
    "adata = AnnData(X = cells[markers].values,\n",
    "                obs = cells.rename(columns={\"cell_id\": \"id\"})[[\"id\"]],\n",
    "                var = pd.DataFrame(index=markers))\n",
    "\n",
    "# Add layers for variables\n",
    "for statistical_descriptor in ['local_90', 'ratio_pixels', 'bin']:\n",
    "    adata.layers[statistical_descriptor] = cells[[\"_\".join([marker, statistical_descriptor]) for marker in markers]].values\n",
    "\n",
    "# Add observations\n",
    "# Note: if you want to redo the leiden or kmeans clustering, you might want to skip adding them\n",
    "for col in [\"size\", \"x\", \"y\", \"leiden\",\t\"leiden_color\",\t\"kmeans\",\t\"kmeans_color\",\t\"kmeans_annotated\",\t\"kmeans_annotated_color\"]:\n",
    "  adata.obs[col] = cells[col].values\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74091fe4",
   "metadata": {},
   "source": [
    "We need to add some information to relate the AnnData information in the table to the cells detected and shown in the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4ee05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns[\"spatialdata_attrs\"] = {\"region\": [\"labels\"],\n",
    "                                  \"region_key\": \"sample_id\",\n",
    "                                  \"instance_key\": \"id\"}\n",
    "adata.obs[\"sample_id\"] = \"labels\"\n",
    "adata.obs[\"sample_id\"] = adata.obs[\"sample_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = SpatialData(\n",
    "    images={\"images\": Image2DModel.parse(img, dims=(\"c\", \"y\", \"x\"), c_coords=channels)},\n",
    "    labels={\"labels\": Labels2DModel.parse(labels, dims=(\"y\", \"x\"))},\n",
    "    tables={\"table\": TableModel.parse(adata)},\n",
    ")\n",
    "sdata.write(sdata_file, overwrite=True)\n",
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77aa414",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91aac7b",
   "metadata": {},
   "source": [
    "For clustering, we could use scanpy over the AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "sc.pp.normalize_total(sdata[\"cells\"])\n",
    "sc.pp.log1p(sdata[\"cells\"])\n",
    "sc.pp.pca(sdata[\"cells\"])\n",
    "sc.pp.neighbors(sdata[\"cells\"])\n",
    "sc.tl.umap(sdata[\"cells\"])\n",
    "sc.tl.leiden(sdata[\"cells\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a4a56",
   "metadata": {},
   "source": [
    "After this step, we would reanalyze and maybe annotate again the clusters found."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
